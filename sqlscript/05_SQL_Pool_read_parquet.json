{
	"name": "05_SQL_Pool_read_parquet",
	"properties": {
		"content": {
			"query": "-- Lab - SQL Pool - External Tables - Parquet\n\nCREATE MASTER KEY ENCRYPTION BY PASSWORD = 'P@ssw0rd@123';\n\n\n\n-- Here we are using the Storage account key for authorization\n\nCREATE DATABASE SCOPED CREDENTIAL SasToken\nWITH IDENTITY='SHARED ACCESS SIGNATURE'\n, SECRET = 'sp=r&st=2023-12-30T03:28:48Z&se=2023-12-30T11:28:48Z&spr=https&sv=2022-11-02&sr=c&sig=izZtTL3McscFJ%2Bse%2FVYzB0Tio%2FrnMuyAP1mA7SlgAXw%3D';\n\n\n\n-- When it comes to Dedicated SQL pool\n-- https://learn.microsoft.com/en-us/azure/synapse-analytics/sql/create-use-external-tables\n-- For CSV files, we need to use the Hadoop driver in the TYPE when mentioning the data source\n-- But if we do this, we get the error Hadoop \n-- The native driver is supported for Partquet based files\n\n\n\nCREATE EXTERNAL DATA SOURCE log_data_parquet\nWITH (    LOCATION   = 'https://storagedatalake201.blob.core.windows.net/parquet',\n          CREDENTIAL = SasToken\n)\n\n\nCREATE EXTERNAL FILE FORMAT parquetfile  \nWITH (  \n    FORMAT_TYPE = PARQUET,  \n    DATA_COMPRESSION = 'org.apache.hadoop.io.compress.SnappyCodec'  \n);\n\n\n\n\nCREATE EXTERNAL TABLE [logdata_parquet]\n(\n    [Correlationid] [varchar](200) NULL,\n\t[Operationname] [varchar](200) NULL,\n\t[Status] [varchar](100) NULL,\n\t[Eventcategory] [varchar](100) NULL,\n\t[Level] [varchar](100) NULL,\n\t[Time] [varchar](500) NULL,\n\t[Subscription] [varchar](200) NULL,\n\t[Eventinitiatedby] [varchar](1000) NULL,\n\t[Resourcetype] [varchar](1000) NULL,\n\t[Resourcegroup] [varchar](1000) NULL,\n    [Resource] [varchar](2000) NULL)\nWITH (\n LOCATION = '/log.parquet',\n    DATA_SOURCE = log_data_parquet,  \n    FILE_FORMAT = parquetfile\n)\n\n\n\n\nSELECT top 10 * FROM logdata_parquet\n\n\n\n\n\n",
			"metadata": {
				"language": "sql"
			},
			"currentConnection": {
				"databaseName": "sqlpooldb",
				"poolName": "sqlpooldb"
			},
			"resultLimit": 5000
		},
		"type": "SqlQuery"
	}
}